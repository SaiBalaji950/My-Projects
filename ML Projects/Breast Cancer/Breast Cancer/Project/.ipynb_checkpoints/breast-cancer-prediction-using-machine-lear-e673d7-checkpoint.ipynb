{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7dc2f0f0-7f2e-441b-ad5e-dc6c6e7e19b5",
    "_uuid": "944c75ecf0178c6158c015537796631f4be3ba67"
   },
   "source": [
    "## Prediction of Breast Cancer using SVM with 99% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e06041ba-c4de-404d-b427-67773487cebb",
    "_uuid": "3ffdd62aeaec4f87cefa896ee8f46fba8ac12876"
   },
   "source": [
    "Using the Breast Cancer Wisconsin (Diagnostic) Database, we can create a classifier that can help diagnose patients and predict the likelihood of a breast cancer. A few machine learning techniques will be explored. In this exercise, Support Vector Machine is being implemented with 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5c7e9232-776b-4250-bc66-846d0211a8d6",
    "_execution_state": "idle",
    "_uuid": "44a9940e9fc2880db72ff036201617f1e2dcc2ac"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10a5454a-2edb-4b71-95ce-cf3eb42ad08d",
    "_uuid": "9de448d38725cef68acd836b44c1f6cae2a280a4"
   },
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Load the dataset and do some quick exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "991fcaa2-e4b6-4d1e-a480-c5335249546a",
    "_execution_state": "idle",
    "_uuid": "7175ebe2ad5a61144de6985dd44398f0c7778a76"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:688\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    635\u001b[0m     engine_specified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    637\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    638\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m    639\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    685\u001b[0m     skip_blank_lines\u001b[38;5;241m=\u001b[39mskip_blank_lines,\n\u001b[0;32m    686\u001b[0m )\n\u001b[1;32m--> 688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:454\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    451\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(fp_or_buf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:948\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1180\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m CParserWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:2010\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m=\u001b[39m _validate_usecols_arg(kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   2008\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m-> 2010\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m   2013\u001b[0m passed_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:382\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('BreastCancer.csv', index_col=False)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f5a9ef3-2b7e-40f3-94c9-d610c0f88dc5",
    "_uuid": "769147a9ae9ba27e572d07c2e75aa9b13287ee9b"
   },
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dfdb2cf8-9fe1-4efb-a779-9cb062a04c71",
    "_uuid": "54c91f25e50f6b069ed7217c34df68cd52cd5970"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd03fdb7-3144-4150-92de-a3f2132f233d",
    "_uuid": "24c05ec20cf1358ff6fda1a37e338f020017caf8"
   },
   "source": [
    "## Data visualisation and pre-processing\n",
    "\n",
    "First thing to do is to enumerate the diagnosis column such that M = 1, B = 0. Then, I set the ID column to be the index of the dataframe. Afterall, the ID column will not be used for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ab2f1c6-b174-4a0a-bf9f-7c94326b3e61",
    "_execution_state": "idle",
    "_uuid": "7bea9ce154dbe82c5d29588f2e27f00bfe3fdf1d"
   },
   "outputs": [],
   "source": [
    "data['diagnosis'] = data['diagnosis'].apply(lambda x: '1' if x == 'M' else '0')\n",
    "data = data.set_index('id')\n",
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "14412b26-d247-41ee-880f-f361a88e4110",
    "_uuid": "81ac236c6c3c0e8206956433426a02779479c094"
   },
   "source": [
    "Let's take a look at the number of Benign and Maglinant cases from the dataset. From the output shown below, majority of the cases are benign (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5936456-74bf-4c42-824f-1973566313c3",
    "_execution_state": "idle",
    "_uuid": "1ec0c60db5f383231016f03dd8e8ff362b08dbc6"
   },
   "outputs": [],
   "source": [
    "print(data.groupby('diagnosis').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c027c06-7285-4bd4-b2c4-ad21e1e293da",
    "_uuid": "6baf17aab6d5183b80e7f3a9aadaca3dded6c3b6"
   },
   "source": [
    "Next, we visualise the data using density plots to get a sense of the data distribution. From the outputs below, you can see the data shows a general gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5457977-bd86-4a6f-87da-8d1acc361852",
    "_execution_state": "idle",
    "_uuid": "40e65d54d983261df308a4aa138b649e4b86725a"
   },
   "outputs": [],
   "source": [
    "data.plot(kind='density', subplots=True, layout=(5,7), sharex=False, legend=False, fontsize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8b3bc827-7651-4be4-800a-e16727af83bc",
    "_uuid": "61fd93395d08de8251226f954320b8cbf4c02871"
   },
   "source": [
    "It is good to check the correlations between the attributes. From the output graph below, The red around\n",
    "the diagonal suggests that attributes are correlated with each other. The yellow and green patches suggest some moderate correlation and the blue boxes show negative correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7025c069-528a-4f68-902d-6964ccbb2eb5",
    "_execution_state": "idle",
    "_uuid": "30721fd7c6e1b4bc1b4c711db44a094969a92b1e"
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm as cm\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "cmap = cm.get_cmap('jet', 30)\n",
    "cax = ax1.imshow(data.corr(), interpolation=\"none\", cmap=cmap)\n",
    "ax1.grid(True)\n",
    "plt.title('Breast Cancer Attributes Correlation')\n",
    "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "fig.colorbar(cax, ticks=[.75,.8,.85,.90,.95,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "80f7e0c1-4e55-4803-bf95-e16e41994a07",
    "_uuid": "dacd3192e8f4b70e41d714beea8c537a1d5faac6"
   },
   "source": [
    "Finally, we'll split the data into predictor variables and target variable, following by breaking them into train and test sets. We will use 20% of the data as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5f9262f-40c7-4935-9e72-f9be15e113e1",
    "_uuid": "770c88e9d8f8f5f0744046d593942f6d7efe1ec5"
   },
   "outputs": [],
   "source": [
    "Y = data['diagnosis'].values\n",
    "X = data.drop('diagnosis', axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6eb9751e-a4e4-457e-b0e3-728334b80999",
    "_uuid": "e85ea911c9057cda526ed82e742c1fa3daff5746"
   },
   "source": [
    "## Baseline algorithm checking\n",
    "\n",
    "From the dataset, we will analysis and build a model to predict if a given set of symptoms lead to breast cancer. This is a binary classification problem, and a few algorithms are appropriate for use. Since we do not know which one will perform the best at the point, we will do a quick test on the few appropriate algorithms with default setting to get an early indication of how each of them perform. We will use 10 fold cross validation for each testing.\n",
    "\n",
    "The following non-linear algorithms will be used, namely: **Classification and Regression Trees (CART)**, **Linear Support Vector Machines (SVM)**, **Gaussian Naive Bayes (NB)** and **k-Nearest Neighbors (KNN)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9d75c60c-5a84-4cf1-abc4-83ccf1a04ea5",
    "_uuid": "1b6ac44446c91123c1ceb2bd027e60ab5eb35b9c"
   },
   "outputs": [],
   "source": [
    "models_list = []\n",
    "models_list.append(('CART', DecisionTreeClassifier()))\n",
    "models_list.append(('SVM', SVC())) \n",
    "models_list.append(('NB', GaussianNB()))\n",
    "models_list.append(('KNN', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3919d00-b7aa-4d62-b438-ee822ed6e50e",
    "_uuid": "971d250d87e73a7f30cc137e4625c30d8c5331c8"
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models_list:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=123)\n",
    "    start = time.time()\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    end = time.time()\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print( \"%s: %f (%f) (run time: %f)\" % (name, cv_results.mean(), cv_results.std(), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04fa9fd2-636c-4f94-94b8-1c9230c85a5a",
    "_uuid": "cc6a875d67a7d600f983e565332843fa98254f9e"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Performance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5f330ec-666a-4ee6-85c8-bd06389005d9",
    "_uuid": "894f687f2f616f40217321a2690ff36d0789ca50"
   },
   "source": [
    "From the initial run, it looks like GaussianNB, KNN and CART performed the best given the dataset (all above 92% mean accuracy). Support Vector Machine has a surprisingly bad performance here. However, if we standardise the input dataset, it's performance should improve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71509d84-7641-4321-a7d2-60f77deb1e4a",
    "_uuid": "c2e22d7495f32f54e7a6f9971503b38a71a210f4"
   },
   "source": [
    "## Evaluation of algorithm on Standardised Data\n",
    "\n",
    "The performance of the few machine learning algorithm could be improved if a standardised dataset is being used. The improvement is likely for all the models. I will use pipelines that standardize the data and build the model for each fold in the cross-validation test harness. That way we can get a fair estimation of how each model with standardized data might perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d8b48313-697e-46cd-8a24-c862912e77cd",
    "_uuid": "2c785e3b14836708690209ac1249220ea98c2592"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART',\n",
    "                                                                        DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC( ))])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB',\n",
    "                                                                      GaussianNB())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN',\n",
    "                                                                       KNeighborsClassifier())])))\n",
    "results = []\n",
    "names = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    kfold = KFold(n_splits=num_folds, random_state=123)\n",
    "    for name, model in pipelines:\n",
    "        start = time.time()\n",
    "        cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "        end = time.time()\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print( \"%s: %f (%f) (run time: %f)\" % (name, cv_results.mean(), cv_results.std(), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5595bdce-4044-4a29-93ba-3003efdbc4fe",
    "_uuid": "09c717fbeeaf8622c7328733812f93f0f1183a43"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Performance Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10287c3c-59a8-492a-aead-13bef7ba71d1",
    "_uuid": "6f63b31910e59133a0d05d2fa88f93b14092cdd1"
   },
   "source": [
    "Notice the drastic improvement of SVM after using scaled data. \n",
    "\n",
    "Next, we'll fine tune the performance of SVM by tuning the algorithm\n",
    "\n",
    "## Algorithm Tuning - Tuning SVM\n",
    "\n",
    "We will focus on SVM for the algorithm tuning. We can tune **two** key parameter of the SVM algorithm - the value of C and the type of kernel. The default C for SVM is 1.0 and the kernel is Radial Basis Function (RBF). We will use the grid search method using 10-fold cross-validation with a standardized copy of the sample training dataset. We will try over a combination of C values and the following kernel types 'linear', 'poly', 'rbf' and 'sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57e17e0e-7eb1-493b-9e12-da601aeaca30",
    "_uuid": "68186b006294aa46d3cc6f9858445fc009c3e7c0"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=21)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "094e29a4-0b77-4578-995d-7aa600e4fcb8",
    "_uuid": "8a4634f59a3d171ef5d48a67d7961a7ffd8134ba"
   },
   "source": [
    "We can see the most accurate configuration was SVM with an **RBF** kernel and **C=1.5**, with the accuracy of **96.92%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b59e3fd3-9b58-4ec9-8129-bd43dfbecd13",
    "_uuid": "8975c42f962cc0bde2f8ed8e763b021110e34b8f"
   },
   "source": [
    "## Application of SVC on dataset\n",
    "\n",
    "Let's fit the SVM to the dataset and see how it performs given the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d22dbf43-8e52-45be-90f1-e93239d624e2",
    "_uuid": "56cdb1896c4c52b05e655485efbc433a770cebd6"
   },
   "outputs": [],
   "source": [
    "# prepare the model\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "model = SVC(C=2.0, kernel='rbf')\n",
    "start = time.time()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "end = time.time()\n",
    "print( \"Run Time: %f\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "062dac6f-e9dd-45f3-bbce-ef55d921b43f",
    "_uuid": "7ee346d6b8f2a86c8b51b8237dceed178737ca4c"
   },
   "outputs": [],
   "source": [
    "# estimate accuracy on test dataset\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "334688fe-9900-4872-a0f9-ab2758964d89",
    "_uuid": "fafb1fdc0bd04148e85c9e069aff39c78e06ddc8"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy score %f\" % accuracy_score(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "158e4ad0-e901-4769-bc61-b9cdc310813f",
    "_uuid": "73b0c7c8bf76432b2d98b8978e031397d0055c55"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93e258f1-8725-4f6b-9ee5-7b360cc77952",
    "_uuid": "e4d054eadfabe28710fe9eb5e49207c1ae2e6969"
   },
   "source": [
    "We can see that we achieve an accuracy of 99.1% on the held-out test dataset. From the confusion matrix, there is only 1 case of mis-classification. The performance of this algorithm is expected to be high given the symptoms for breast cancer should exchibit certain clear patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "711380de-5eea-43ca-8aa0-0ea788c3593a",
    "_uuid": "21e532367c3d9ad464471ecdb51df70f839ee0b7"
   },
   "source": [
    "## What else could be done\n",
    "\n",
    "1. Test the algorithm on KNN and GausianNB\n",
    "2. Test the data with Artificial Neural Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6c26a28-063c-4efb-916f-81e5f1eaa202",
    "_uuid": "2c6792f4b693836e7af04656b0b9bb70c3384705",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "f9SY5",
   "launcher_item_id": "oxndk",
   "part_id": "mh1Vo"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 180,
     "sourceId": 408,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
